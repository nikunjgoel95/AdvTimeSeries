---
title: "chapter2_1"
author: "Nikunj Goel"
date: "9/8/2020"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Including libraries

```{r}
library(astsa)
```

## 2.1

In stationarity the statistical properties of a process generating a time series do not change over time. It is important because they are easier to analyze, model and investigate. These processes should be possible to predict, as the way they change is predictable.

## 2.2

### Part a)

Mean of the time series $x_{t}$ would be

$$\mu_{x,t} = \text E(x_{t}) = \beta_{0} + \beta_{1}t$$

which is not independent of time. It violates the first rule of time series stationarity and is not *Stationary*.

### Part b)

$$y_{t} = x_{t} - x_{t-1}$$

Replacing the value of $x_{t}$ in the equation above.

$$
y_{t} = (\beta_{0}+\beta_{1}t+w_{t}) - (\beta_{0}+\beta_{1}(t-1)+w_{t-1})\\
\\
y_{t} = \beta_{1} + w_{t} - w_{t-1}\\
\\
\mu_{y,t} = \text E(y_{t}) = \beta_{1}
$$

The mean is constant and does not depend on time $t$.

$$
cov(y_{t+h},y_{t}) = cov((w_{t+h} - w_{t+h-1} + \beta_{1}),(w_{t} - w_{t-1} + \beta_{1}))\\
$$
The covariance of (constant,variable) and covariance of (constant,constant) is zero. So the equation reduces to
$$
cov(y_{t+h},y_{t}) = cov(w_{t+h},w_{t}) - cov(w_{t+h},w_{t-1}) -  cov(w_{t+h -1},w_{t}) + cov(w_{t+h-1},w_{t-1})
$$

For h=0

$$2\sigma_{w}^2$$

For h=1 and h=-1

$$-\sigma_{w}^2$$

For other h 

$$0$$

Which proves that the process is stationary.

### Part c)

$$
\mu_{v,t} = 1/3E[(\beta_{0} + \beta_{1}(t-1) + w_{t-1} + \beta_{0} + \beta_{1}(t) + w_t + \beta_{0} + \beta_{1}(t+1) + w_{t+1})]
\\
\mu_{v,t} = 1/3E[(3\beta_{0} + 3\beta_{1}t + w_{t-1} + w_{t} + w_{t+1})]
\\
\mu_{v,t} = \beta_{0} + \beta_{1}t
$$


## 2.3

The equation is
$$
x_{t} = \dfrac{1}{4}(w_{t-1} + 2w_{t} + w_{t+1})
$$
AutoCovariance of the equation is

$$
cov(x_{t+h},x_{t}) = [\dfrac{1}{4}(w_{t+h-1} + 2w_{t+h} + w_{t+h+1}),\dfrac{1}{4}(w_{t-1} + 2w_{t} + w_{t+1})]
\\
=\dfrac{1}{16}[(w_{t+h-1} + 2w_{t+h} + w_{t+h+1}),(w_{t-1} + 2w_{t} + w_{t+1})]
\\
\text for \ h=0
\\
cov(x_{t+h},x_{t}) = \dfrac{1}{16}[6\sigma_{w}^2]
\\
\text for \ h=\pm 1 
\\
cov(x_{t+h},x_{t}) = \dfrac{1}{16}[4\sigma_{w}^2]
\\
\text for \ h=\pm 2
\\
cov(x_{t+h},x_{t}) = \dfrac{1}{16}[\sigma_{w}^2]
$$
As we can see,
$$
\mu_{x,t} = \dfrac{1}{4}E(w_{t-1} + 2w_{t} + w_{t+1})
\\
= 0
$$
As the mean of the time series is time independent and the CoVoriance depends on the time difference So this means the the time series $x_{t}$ is **stationary**.

So AutoCorrelation is

$$
\rho_x(h) = \dfrac{\gamma(h)}{\gamma(0)}
\\
\rho_x(h) = \begin{cases}
1, & \text{h=0}
\\
\frac{4}{6}, & \text{h=$\pm$1}
\\
\frac{1}{6}, & \text{h=$\pm$2}
\\
0, & \text{otherwise}
\end{cases}
$$

```{r}
ACF = c(0,0,0,1,4,6,4,1,0,0,0)/6
LAG = -5:5
tsplot(LAG,ACF,type='h',lwd=3,xlab="LAG")
abline(h=0)
points(LAG[-(4:8)],ACF[-(4:8)], pch=20)
axis(1,at=seq(-5,5, by=2))
```

## 2.4

### Part a)

$$
x_{t} = \phi.x_{t-1} + w_{t}
\\
\mu_{x,t} = \phi.E(x_{t-1}) + E(w_{t})
\\
$$

As $x_{t-1}$ is uncorrelated with $w_{t}$ and $phi$ cannot be one. So only condition that will satisfy is :-
$$
\mu_{x,t} = 0
$$

### Part b)

$$
\gamma_{x}(0) = var(x_{t}) = var(\phi.x_{t-1} + w_{t})
\\
\gamma_{x}(0) = var(x_{t}) = var(\phi.x_{t-1}) + var(w_{t}) + 2cov(\phi.x_{t-1},w_{t})
\\
\gamma_{x}(0) = var(x_{t}) = \phi^2var(x_{t-1}) + var(w_{t})
\\
\gamma_{x}(0) =  var(x_{t}) = \phi^2\gamma_{x}(0) + 1
\\
\gamma_{x}(0) = \dfrac{1}{(1-\phi^2)}
$$

### Part c)

For the values to make sense $|\phi| < 1$

### Part d)

$$
\gamma_x(1) = cov(x_{t},x_{t-1}) = cov(\phi.x_{t-1} + w_{t},x_{t-1})\\
\\
\gamma_x(1) = cov(\phi.x_{t-1}, x_{t-1}) = \phi\gamma_{x}(0)\\
\\
\rho_x(1) = \dfrac{\gamma_x(1)}{\gamma_x(0)} = \phi
$$


## 2.5

### Part a)

Using the equation

$$x_{t} = \delta + x_{t-1} + w_{t} $$
putting t=1

$$
x_{1} = \delta + w_{1}
\\
x_{2} = 2\delta + w_{1} + w_{2}
\\
x_{3} = 3\delta + w_{1} + w_{2} + w_{3}
$$

Assuming it be true for $$x_{t-1} = (t-1)\delta + \sum_{k=1}^{t-1} w_{k}$$

$$
x_{t} = \delta + (t-1)\delta + \sum_{k=1}^{t-1} w_{k} + w_{t}
\\
x_{t} = (t)\delta + \sum_{k=1}^{t} w_{k}
\\
x_{t+1}  = \delta + t\delta + \sum_{k=1}^{t+1} w_{k}
$$

By mathematical induction, we can prove that the form of the term is as mentioned.


### Part b)

Mean of $x_{t}$

$$
\mu_{x,t} = \delta.t + E(\sum_{k=1}^{t} w_{k})
\\
\mu_{x,t} = \delta.t
$$

AutoCovariance of $x_{t}$

$$
cov(x_{t+h},x_{t}) = E[(x_{t+h} - E(x_{t+h}))(x_{t} - E(x_{t}))]
\\
cov(x_{t+h},x_{t}) = cov(\sum_{k=1}^{t+h} w_{k},\sum_{k=1}^{t} w_{k})
\\
cov(x_{t+h},x_{t}) = t.\sigma_{w}^2
$$

### Part c)

Mean of $x_{t}$ depends on time and doesn't follow the first rule of stationarity.

### Part d)

$$
\rho_{x}(t-1,t) = \dfrac{\gamma_{x}(t-1,t)}{\sqrt{\gamma_x(t-1,t-1)\gamma_x(t,t)}}
\\
\rho_{x}(t-1,t) = \dfrac{cov(x_{t},x_{t-1})}{\sqrt{cov(x_{t-1},x_{t-1})cov(x_{t},x_{t})}}
\\
\rho_{x}(t-1,t) = \dfrac{(t-1)\sigma_{w}^2}{\sqrt{(t-1)\sigma_{w}^2(t)\sigma_{w}^2}}
\\
\rho_{x}(t-1,t) = \sqrt{\dfrac{t-1}{t}}
\\
\rho_{x}(t-1,t) = \lim_{t \to +\infty} \sqrt{1-\dfrac{1}{t}}
\\
\rho_{x}(t-1,t) = 1
$$
This implies that as time goes on $\infty$ the ACF loses it's power.

### Part e)

To make the series **Stationary** we might try differencing: 
$$
y_{t} = x_{t} - x_{t-1}
\\
y_{t} = \delta + x_{t-1} + w_{t} - x_{t-1}
\\
y_{t} = \delta + w_{t}
$$
Check Stationary
$$
E(y_{t}) = E(\delta + w_{t}) 
\\
E(y_{t}) = \delta
$$
Not dependent on t.

ACV: 

$$
\gamma(t+h,t) = cov(x_{t+h},x_{t})
\\
\gamma(t+h,t) = cov(\delta + w_{t+h},\delta + w_{t})
\\
\text when \ h=0
\\
\gamma(t+h,t) = \sigma^2
$$
This Satisfies both stationary conditions. So it is stationary.
