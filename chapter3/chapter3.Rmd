---
title: "Untitled"
author: "Nikunj Goel"
date: "9/26/2020"
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Loading Libraries

```{r}
library(astsa)
```

## 3.1

### Part a)

```{r}
trend = time(jj) - 1970
q = factor(cycle(jj))
req = lm(log(jj) ~ 0 + trend + q, na.action = NULL)
model.matrix(req)
summary(req)
```


### Part b)

The estimated average annual increase in the logged earnings per share is 
$$
q1 + q2 + q3 + q4
$$
which can be extracted from the summary table 

```{r}
1.052793 + 1.080916 + 1.151024 + 0.882266
```

### Part c)

Average logged earning rate $q4$ - $q3$ decreases.
```{r}
0.882266 - 1.151024
```

The percentage of the decrease is 
```{r}
(0.269/1.151024) * 100
```


### Part d)

```{r}
trend = time(jj) - 1970
q = factor(cycle(jj))
req = lm(log(jj) ~ trend + q, na.action = NULL)
summary(req)
```

Having an intercept removes the first quarter away.
Also the intercept appears in all the quarters. It is of no use because we want to analyze all the quarters separately.

### Part e)

```{r}
par(mfrow=c(1,2))
plot(log(jj), main="plot of data and fitted value")
lines(fitted(req), col="red") 
plot(log(jj) - fitted(req), main="plot of residuals")
```


The residuals are not following any pattern hence it looks fairly white.
The fit of the model is decent.

## 3.2

### Part a)

```{r}
temp = tempr - mean(tempr)
temp2 = temp^2
trend = time(cmort)
partL4 = lag(part, -4)

ded = ts.intersect(cmort, trend, temp, temp2, part, partL4)
fit = lm(cmort ~ trend + temp + temp2 + part + partL4, data = ded, na.action = NULL)
summary(fit)
```

**Some conclusion**

### Part b)

```{r}
AIC(fit)/length(cmort) - log(2*pi)
BIC(fit)/length(cmort) - log(2*pi)
```

**Some conclusion on this.**

## 3.4

### Part a)

The equation is 

$$
x_{t} = \beta_{0} + \beta_{1}t + w_{t}
$$
Mean of $x_{t}$

$$
E[x_{t}] = E[\beta_{0} + \beta_{1}t + w_{t}] = \beta_{0} + \beta_{1}t
$$

It is dependent on time t, hence the series $x_{t}$ is not stationary.

### Part b)

The first order difference can be simplified into

$$
\Delta x_{t} = x_{t} - x_{t-1}
\\
= \beta_{0} + \beta_{1}t + w_{t} - [\beta_{0} + \beta_{1}(t-1) + w_{t-1}]
\\
= w_{t} - w_{t-1} + \beta_{1}
$$
Mean of the function would be

$$
E[\Delta x_{t}] = E[w_{t} - w_{t-1} + \beta_{1}]
\\
=\beta_{1} + E[w_{t}] - E[w_{t-1}]
\\
=\beta_{1}
$$

Independent of time

and now Auto Covariance Function is:

$$
\gamma \Delta x_{t}(t+h,h) = Cov(x_{t+h},x_{t})
\\
= Cov(w_{t+h} - w_{t+h-1} + \beta_{1},w_{t} - w_{t-1} + \beta_{1})
\\
= Cov(w_{t+h} - w_{t+h-1},w_{t} - w_{t-1})
\\
\begin{cases}
2 \sigma^2_{w}, & \text{h=0}
\\
-\sigma^2_{w}, & \text{|h| = 1}
\\
0, & \text{|h|>1}
\end{cases}
$$
which is also free from t, hence $\Delta x_{t}$ is stationary.

### Part c)

$$
\gamma \Delta x_{t}(t+h,h) = Cov(x_{t+h},x_{t})
\\
=Cov(\beta_{1} + y_{t+h} - y_{t+h-1},\beta_{1} + y_{t} - y_{t-1})
\\
=Cov(y_{t+h} - y_{t+h-1},y_{t} - y_{t-1})
\\
=Cov(y_{t+h},y_{t}) - Cov(y_{t+h},y_{t-1}) -Cov(y_{t+h-1},y_{t}) + Cov(y_{t+h-1},y_{t-1})
\\
=\gamma_{y}(h+1) - 2\gamma_{y}(h) + \gamma_{y}(h-1)
$$
which is independent of time since $y_{t}$ is stationary and $\gamma_{t}$(·)is independent of time t.
So it is Stationary.

## 3.6

### Part a)

```{r}
n = length(varve)
varve1 = varve[1:n/2]
varve2 = varve[(n/2+1):n]
data.frame(firstHalf = var(varve1),SecondHalf=var(varve2))
```

as we can see the sample variance in the second half of the data is significanlty larger than the first half,therefore the variance is not homogenous, hence we need to statibilize the variance by data transformation such as log(·)-transformation. Having a log transformation obviously made data closer to the normality.

```{r}
par(mfrow= c(1,2))
hist(varve, main="raw data")
hist(log(varve), main="log-transformed data")
```

### Part b)

```{r}
plot(log(varve), main="log-transformed data")
```
It doesn’t seem that there is an increasing/decreasing trend over time.

### part c)

```{r}
acf(log(varve), lag.max = 20)
```
that the dependency in the data is very strong in close lags and dies down very slowly.

### Part d)

```{r}
u = diff(log(varve), 1)
plot(u)
acf1(u)
```



differencing produces fairly reasonable stationary process. $u_{t}$can be interpreted as the yearly increase in the thicknesses varves.

In Statistical sense it can also be smoothing.

$$
u_{t} = \Delta y_{t}
\\
=y_{t} - y_{t-1}
\\
=log(x_{t}) - log(x_{t-1})
\\
=log(\frac{x_{t}}{x_{t-1}})
\\
=log(1 + \frac{x_{t} - x_{t-1}}{x_{t-1}})
\\
\approx \frac{x_{t} - x_{t-1}}{x_{t-1}}
$$
which can be intepreted as the marginal change in the thickness varves.

## 3.7

```{r}
# MA Smoothing
wgts =c(.5,rep(1,11), .5)/12
smooth1 =filter(gtemp, sides=2, filter=wgts)
# Kernel Smoothing
smooth2 =ksmooth(time(gtemp), gtemp, "normal", bandwidth=10)
# Lowess smoothing
smooth3 =lowess(gtemp)
par(mfrow=c(3,1))
plot(gtemp, type="o", ylab="MA Smoothing")
lines(smooth1, col="red")
plot(gtemp, type="o", ylab="Kernel Smoothing")
lines(smooth2, col="red")
plot(gtemp, type="o", ylab="Lowess Smoothing")
lines(smooth3, col="red")
```
All methods seems to model the trend reasonably, but one needs to be careful on picking the tunning parameters such as the weights of MA smoothing, bandwitdh of the kernel smoothing, and so on.
